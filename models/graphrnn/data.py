import networkx as nx
import torch
from joblib import Parallel, delayed

from core.utils import get_n_jobs
from core.serialization import load_pickle, save_pickle
from models.data import BaseDataset, BaseLoader


def calc_max_prev_node_helper(G):
    max_prev_node = []
    for _ in range(100):
        bfs_seq = get_random_bfs_seq(G)
        bfs_order_map = {bfs_seq[i]: i for i in range(len(G.nodes()))}
        G = nx.relabel_nodes(G, bfs_order_map)

        max_prev_node_iter = 0
        for u, v in G.edges():
            max_prev_node_iter = max(max_prev_node_iter, max(u, v) - min(u, v))

        max_prev_node.append(max_prev_node_iter)

    return max_prev_node


def calc_max_prev_node(graphs):
    """
    Approximate max_prev_node from simulating bfs sequences
    """
    P = Parallel(n_jobs=get_n_jobs(), verbose=1)
    max_prev_node = P(delayed(calc_max_prev_node_helper)(G) for G in graphs)
    max_prev_node = sorted(max_prev_node)[-1 * int(0.001 * len(max_prev_node))]
    return max(max_prev_node)


def get_bfs_seq(G, start_id):
    """
    Get a bfs node sequence
    :param G: graph
    :param start_id: starting node
    :return: List of bfs node sequence
    """
    successors_dict = dict(nx.bfs_successors(G, start_id))
    start = [start_id]
    output = [start_id]
    while len(start) > 0:
        succ = []
        for current in start:
            if current in successors_dict:
                succ = succ + successors_dict[current]

        output = output + succ
        start = succ
    return output


def get_random_bfs_seq(graph):
    n = len(graph.nodes())
    # Create a random permutaion of graph nodes
    perm = torch.randperm(n)
    adj = nx.to_numpy_matrix(graph, nodelist=perm.numpy(), dtype=int)
    G = nx.from_numpy_matrix(adj)

    # Construct bfs ordering starting from a random node
    start_id = torch.randint(0, n, ()).item()
    bfs_seq = get_bfs_seq(G, start_id)

    return [perm[bfs_seq[i]] for i in range(n)]


def graph_to_matrix(graph, mapper):
    """
    Method for converting graph to a 2d feature matrix
    :param graph: Networkx graph object
    :param node_map: Node label to integer mapping
    :param edge_map: Edge label to integer mapping
    :param max_prev_node: Number of previous nodes to consider for edge prediction
    :param max_head_and_tail: Head and tail of adjacency vector to consider for edge prediction
    :random_bfs: Whether or not to do random_bfs
    """
    n = len(graph.nodes())
    len_node_map = len(mapper['node_forward'])
    len_edge_map = len(mapper['edge_forward'])
    len_node_vec = len_node_map + 2
    max_prev_node = mapper['max_prev_node']

    bfs_seq = get_random_bfs_seq(graph)
    bfs_order_map = {bfs_seq[i]: i for i in range(n)}
    graph = nx.relabel_nodes(graph, bfs_order_map)

    # 3D adjacecny matrix in case of edge_features (each A[i, j] is a len_edge_vec size vector)
    adj_mat_2d = torch.ones((n, max_prev_node))
    adj_mat_2d.tril_(diagonal=-1)
    adj_mat_3d = torch.zeros((n, max_prev_node, len_edge_map))

    node_mat = torch.zeros((n, len_node_vec))

    for v, data in graph.nodes.data():
        ind = mapper['node_forward'][data['label']]
        node_mat[v, ind] = 1

    for u, v, data in graph.edges.data():
        if abs(u - v) <= max_prev_node:
            elabel =  mapper['edge_forward'][data['label']]
            adj_mat_3d[max(u, v), max(u, v) - min(u, v) - 1, elabel] = 1
            adj_mat_2d[max(u, v), max(u, v) - min(u, v) - 1] = 0

    adj_mat_2d = adj_mat_2d.reshape(adj_mat_2d.size(0), adj_mat_2d.size(1), 1)
    zeros = torch.zeros((n, max_prev_node, 2))
    adj_mat = torch.cat([adj_mat_3d, adj_mat_2d, zeros], dim=2)
    adj_mat = adj_mat.reshape((adj_mat.size(0), -1))

    return torch.cat((node_mat, adj_mat), dim=1)


class Dataset(BaseDataset):
    """
    Dataset for reading graphs from files and returning adjacency like matrices
    max_prev_node has higher precedence than max_head_and_tail i.e
    :param args: Args object
    :param graph_list: List of graph indices to be included in the dataset
    :param feature_map: feature_map for the dataset generated by the mapping
    :random_bfs: Whether or not to do random_bfs
    """

    def __init__(self, name):
        super().__init__(name)
        self.mapper = load_pickle(self.root_dir / "map.dict")

        if 'max_prev_node' not in self.mapper:
            self.mapper['max_prev_node'] = calc_max_prev_node(self.graphs)
            save_pickle(self.mapper, self.root_dir / "map.dict")

        self.max_prev_node = self.mapper['max_prev_node']
        self.max_nodes = self.mapper['max_nodes']

        self.len_node_vec = len(self.mapper['node_forward']) + 2
        self.len_edge_vec = len(self.mapper['edge_forward']) + 3

        self.feature_len = self.len_node_vec + self.max_prev_node * self.len_edge_vec

    def __len__(self):
        return len(self.graphs)

    def __getitem__(self, idx):
        G = self.graphs[idx]
        x_item = torch.zeros((self.max_nodes, self.feature_len))

        # get feature matrix for the min graph
        adj_feature_mat = graph_to_matrix(G, self.mapper)

        # prepare x_item
        x_item[0:adj_feature_mat.shape[0],:adj_feature_mat.shape[1]] = adj_feature_mat

        return {'x': x_item, 'len': len(adj_feature_mat)}


class Loader(BaseLoader):
    def collate(self, batch):
        return {
            "x": torch.stack([b['x'] for b in batch]),
            "len": torch.LongTensor([b['len'] for b in batch])
        }