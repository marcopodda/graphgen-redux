import pickle
from torch.utils.data import Dataset

from dfscode.dfs_wrapper import get_min_dfscode
# from datasets.preprocess import dfscode_to_tensor
from datasets.reduce_dataset import dfscode_to_tensor

# Reduce mindfscode at inference time
# Unknown tokens are masked out
def reduce_dfscode(min_dfscode, dfs_to_reduced, reduced_to_dfs):
  key = len(dfs_to_reduced)
  reduced_list = []

  for quintuple in min_dfscode:
    if quintuple[2:] in reduced_to_dfs.values():
      # Find token associated to that triple
      k = tuple(quintuple[2:])
      token = dfs_to_reduced[k]
      reduced_list.append(quintuple[:2]+[token])
    elif list(reversed(quintuple[2:])) in reduced_to_dfs.values():
      k = tuple(reversed(quintuple[2:]))
      token = dfs_to_reduced[k]
      reduced_list.append(quintuple[:2]+[token])
    else:
      reduced_list.append(quintuple[:2]+[key])

  
  return reduced_list

class Graph_DFS_code_from_file(Dataset):
    """
    Dataset for reading graphs from files and returning matrices
    corresponding to dfs code entries
    :param args: Args object
    :param graph_list: List of graph indices to be included in the dataset
    :param feature_map: feature_map for the dataset generated by the mapping
    """

    def __init__(self, args, graph_list, feature_map, reduced_map):
        # Path to folder containing dataset
        self.dataset_path = args.current_processed_dataset_path
        self.graph_list = graph_list
        self.feature_map = feature_map
        self.reduced_map = reduced_map
        self.temp_path = args.current_temp_path

        self.max_edges = feature_map['max_edges']
        max_nodes = feature_map['max_nodes']
        len_token = len(reduced_map['dfs_to_reduced']) + 1
        self.feature_len = 2 * (max_nodes + 1) + len_token

    def __len__(self):
        return len(self.graph_list)

    def __getitem__(self, idx):
        with open(self.dataset_path + 'graph' + str(self.graph_list[idx]) + '.dat', 'rb') as f:
            dfscode_tensors = pickle.load(f)

        return dfscode_tensors

# Testin time Dataset for loading graphs into network-feedable format
class Graph_DFS_code(Dataset):
    """
    Given loaded graphs, returns tensor-reduced-min-dfscodes
    :param args: Args object
    :param graph_list: List of graph indices to be included in the dataset
    :param feature_map: feature_map for the dataset generated by the mapping
    """

    def __init__(self, args, graph_list, feature_map, reduced_map):
        # Path to folder containing dataset
        self.graph_list = graph_list
        self.feature_map = feature_map
        self.reduced_map = reduced_map
        self.temp_path = args.current_temp_path

        self.max_edges = feature_map['max_edges']
        max_nodes, len_node_vec, len_edge_vec = feature_map['max_nodes'], len(
            feature_map['node_forward']) + 1, len(feature_map['edge_forward']) + 1
        len_token = len(reduced_map['reduced_to_dfs']) + 1
        self.feature_len = 2 * (max_nodes + 1) + len_token

    def __len__(self):
        return len(self.graph_list)

    def __getitem__(self, idx):
        G = self.graph_list[idx]

        # Get min DFS code
        min_dfscode = get_min_dfscode(G)
        # # Get reduced min DFS code
        red_dfscode = reduce_dfscode(min_dfscode, self.reduced_map['dfs_to_reduced'], self.reduced_map['reduced_to_dfs'])
        # # Get tensor reduced min DFS code
        tensor_dfscode = dfscode_to_tensor(red_dfscode, self.feature_map, self.reduced_map)

        # return tensor_dfscode
        return tensor_dfscode